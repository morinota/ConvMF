# 参考

- 自然言語処理における畳み込みニューラルネットワークを理解する
  - https://tkengo.github.io/blog/2016/03/11/understanding-convolutional-neural-networks-for-nlp/
- PyTorchを使ってCNNで文章分類を実装してみた
  - https://qiita.com/m__k/items/6c39cfe7dfa99102fa8e
- A Complete Guide to CNN for Sentence Classification with PyTorch
  - https://chriskhanhtran.github.io/posts/cnn-sentence-classification/

# 自然言語処理における畳み込みニューラルネットワークを理解する

## 畳み込みとは?

畳み込みについては、行列に適用されるスライド窓関数 (sliding window function) として考えるとわかりやすい。

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/convolution_schematic.gif)

スライド窓は**カーネル(kernel)**や**フィルタ(filter)**または**特徴検出器(Feature Detector)**等と呼ばれる。

- 上の例では3×3のフィルタを使っており、そのフィルタの値と行列の値を**要素毎にかけ合わせ**、それらの値を**合計したもの**を、COnvoloved Featureの**一つの要素とする**。
- この操作を、行列全体をカバーするように、フィルタをスライドさせながら行い、全体の畳み込み特徴(Covolved Feature)を取得する。

結局これで何ができるのか？以下で直感的な例を挙げていく.

## 畳み込みニューラルネットワークとは?

CNN は、ReLU や tanh のような非線形な活性化関数を通した、いくつかの畳み込みの層のこと。

伝統的な順伝搬型ニューラルネットワークでは、**それぞれの入力ニューロンは次の層のニューロンにそれぞれ接続**されており、これは**全結合層**や**アフィン層**とも呼ばれる。

しかし CNN ではそのようなことはせずに、ニューロンの出力を計算するのに畳み込みを使う。これによって、**入力となるニューロンのある領域が、それぞれ対応する出力のニューロンに接続されているような、局所的な接続ができる**ことになる。

各層は別々の異なるフィルタを適用し、(これは一般的には 100 〜 1000 程度の数になるが) それらを結合する。(この結合する層を**プーリング層(subsampling)**と呼ぶ。)

CNNの学習フェーズでは、解決したいタスクに適応できるように、**フィルタの値(=スライド窓行列=カーネルの各要素！)を自動的に学習していく**。

- 例えば画像分類の話でいうと、
  - CNNは最初の層で生のピクセルデータからエッジを検出する為の学習を進め、
  - そのエッジを使って今度は次の層で単純な形状を検出し、
  - 更により深い層ではその形状を使ってより高レベルな特徴、つまり顔の形状等の特徴を検出するようになる。
  - そして最後の層は、高レベルな特徴を使った(=入力とした)分類器になる。

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/convolutional-neural-network-overview.png)

さて、畳み込み計算には注目すべき点が２つある。**位置不変性(Location Invariance)**と**構成性(Compositionality)**である。

- 位置不変性(Location Invariance)
  - 例えば、画像の中に象が写っているかどうかを判別したいとする。
  - 畳み込み層では画像全体にわたってフィルタをスライドさせていくので、**画像中のどこに象が現れるのか**を気にしなくてもよい。
  - またプーリング層でも、平行移動、回転、スケーリングに対して不変性を得ることができるが、これは後述。
- 構成性(Compositionality)
  - 各フィルタは、**低レベルな特徴である画像の一区画から、より高レベルな特徴を表現**できるようにしてくれる。
  - これがコンピュータービジョンにおいて CNN が非常に強力である理由！！
  - ピクセルからエッジを、エッジから形状を、そしてその形状からより複雑なオブジェクトを構築する、という流れは直感的に理にかなっている。

## これらをどうやってNLPへ適用するのか?

画像分類では入力は画像のピクセル行列になるが、**ほとんどの NLP タスクではピクセル行列の代わりに、行列で表現された文章または文書が入力**となる。

- 行列の**各行は 1 つのトークンに対応**しており、一般的には単語がトークンになることが多いが、文字がトークンのケースもある。
- ＝＞すなわち、**各行は単語を表現するベクトル**。
  - 普通、これらのベクトルは word2vec や GloVe のような低次元な単語埋め込み表現 (word embeddings) を使う。one-hot ベクトルのケースもある。

例えば、**100 次元の単語埋め込みを使った 10 単語の文章があった場合、10x100 の行列となる**。これがNLPにおける"画像"になる。

- コンピュータビジョンでは、フィルタは画像のある区画上をスライドしていくが、NLP では一般的に**行列の行全体 (つまり単語毎) をスライドする**フィルタを使う。
  - つまり、**フィルタの幅(横幅)は入力となる行列の幅と同じ**になる!
  - つまり、NLPの場合のフィルタ(スライド窓, カーネル, 特徴検出器)は横方向にはスライドせず、縦方向にのみスライドしていく！
- フィルタの高さ(縦幅)は様々だが、一般的には2~5くらいの単語くらい?
-

これらのことを加味すると NLP の畳み込みニューラルネットワークはこんな感じになる。

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/convolutional-neural-network-for-nlp-without-pooling.png)

上図の解釈

- 文章分類のための畳み込みニューラルネットワーク (CNN) のアーキテクチャを説明した図.
- 畳み込み層
  - この図には 2、3、4 の高さをもったフィルタが、それぞれ 2 つずつ(計6)ある。
  - 各フィルタは文章の行列上で**畳み込み**を行い、特徴マップ(〇行1列のやつ)を生成する。
- プーリング層
  - 各特徴マップに対して最大プーリングをかけていき、**各特徴マップの中で一番大きい値を記録していく**。
  - そして、全 6 つの特徴マップから単変量な特徴 (univariate feature) が生成され、それら 6 つの特徴は結合されて、それが最後から 2 番目の層になる。
- 全結合層(アフィン層)(一層？出力層？)
  - 一番最後の softmax 層では先程の特徴を入力として受け取り、文章を分類する。
  - ここでは二値分類を前提としているので、最終的には 2 つの出力がある。

### NLPの場合の位置不変性と構成性について

位置不変性と構成性は、画像においては直感的にわかるが、NLP の場合はそうではない。
**NLP ではたぶん、文章内で単語が出現する場所なんかを気にする**んじゃないだろうか。
お互いに近くにあるピクセル同士は意味的に関連している、つまりは同じオブジェクトであると言えると思うが、単語においてそれは常にそうとは限らない。
多くの言語において、フレーズの一部は単語によって区切ることができる。こういった文章の組成は明確なものではない。
単語のより高レベルな表現 (たとえば実際の単語の “意味” など) はピュータービジョンほど明らかではなく、一体この NLP に対する CNN はどうやって動作しているのか？

### NLPにCNNを使っていいのか...?

こうなると、CNN は NLP のタスクにはうまく適合しないんじゃないかという気がしてくる。
リカレントニューラルネットワーク(RNN)はもっと直感的だし、実際に人間が言語を処理するやり方に似ている。(左から右に順番に読んでいく方法!系列データとして！！)

とは言っても、これまでの説明は決して CNN がうまく動かないという意味ではない。
完璧なモデルなど無いが、それでも役に立つモデルはある という言葉がありますが、NLP の問題へ適用された CNN は、結果的にはとてもよい性能を発揮する。

単純な Bag of Words モデル は誤った仮定のもと単純化しすぎなのは明らかだが、にもかかわらずしばらくは一般的なアプローチであり、人々はそれを使ってより良い結果を得ようとしてきた。

### CNNをNLPに使うメリット！

CNN を使う言い分としては、とても速いということ。
畳み込みはコンピューターグラフィックスにおいて重要なものであり GPU 上にハードウェアレベルで実装されている。
n-grams のようなものと比べて CNN は効率的に単語を表現できる。
ボキャブラリーが巨大な場合、3-grams 以上のものは計算量が多すぎてすぐに計算できなくなる。
Google でさえ 5-grams を超えるものは提供していない。
畳み込みフィルタはボキャブラリー全体を表現する必要なく、勝手に適切な表現を学習してくれる。
最初の層にあるたくさんの学習済みのフィルタは n-grams と非常に良く似た特徴を捉えるが、よりコンパクトな表現を得ることができると考えると良いだろう(しかも計算量が多すぎて計算ができないといった制限もない)。

# CNNのハイパーパラメータ

CNN を NLP へ適用するやり方を説明する前に、CNN を構築する際に必要となってくるものがいくつかある。きっと CNN 理解の手助けとなるはず。

## 畳み込み幅のサイズ

最初に畳み込みの説明をした時、フィルタ(スライド窓、カーネル、特徴検出器)を適用する際の詳細について説明を飛ばしたものがある。

行列の真ん中辺りに 3x3 のフィルタを適用するのは問題ないが、それではフチの辺りに適用する場合はどうなんだろうか??
行列の左側にも上側にも隣接した要素がないような、たとえば行列の最初の要素にはどうやってフィルタを適用すればよいのだろうか？

そういった場合には、**ゼロパディング**が使える！
行列の外側にはみ出してしまう要素は全て 0 で埋めるのである。
こうすることで、入力となる行列の全要素にわたってフィルタを適用することができる。

**ゼロパディングを行うことは wide convolution**とも呼ばれ、逆に**ゼロパディングをしない場合は narrow convolution**と呼ばれる。

以下は1次元での例：
(Narrow Convolution と Wid Convolution。フィルタのサイズは 5 で、入力データのサイズは 7。)

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/narrow_vs_wide_convolution.png)

**入力データのサイズに対してフィルタサイズが大きい時**には wide convolution が有用。
上記の場合、narrow convolution は出力されるサイズが $(7 - 5) + 1 = 3$ になり、wide convolutin は $(7 + 2 * 4 - 5) + 1 = 11$ になる。
一般化すると、wide convolutionの場合の出力サイズ(畳み込み層の出力=特徴マップの大きさ?)は $n_{out}=(n_{in} + 2*n_{padding} - n_{filter}) + 1$である。

## ストライド

**ストライド**という畳み込みのもう一つのハイパーパラメータがある。
これはフィルタを順に適用していく際に、**フィルタをどれくらいシフトするのか**という値。
これまでに示してきた例は全てストライド=1 で、フィルタは重複しながら連続的に適用されている。

ストライドを大きくするとフィルタの適用回数は少なくなって、出力のサイズも小さくなる。

以下のような図が Stanford cs231 にあるが、これは 1 次元の入力に対して、ストライドのサイズが 1 または 2 のフィルタを適用している様子。
(畳み込みのストライドのサイズ。左側のストライドは 1。右側のストライドは 2)

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/stride.png)

**普通、文書においてはストライドのサイズは 1**だが、ストライドのサイズを大きくすることで、例えばツリーのような 再帰型ニューラルネットワーク と似た挙動を示すモデルを作れるかもしれない...!

## プーリング層

畳み込みニューラルネットワークの鍵は、畳み込み層の後に適用されるプーリング層である。
プーリング層は、入力をサブサンプリングする。

最も良く使われるプーリングは、各フィルタの結果(=各畳み込み層の出力=特徴マップ)の中から最大値を得る操作である。
ただ、畳み込み結果の行列全体にわたってプーリングする必要はなく、指定サイズのウィンドウ上でプーリングすることもできる。
たとえば、以下の図は 2x2 のサイズのウィンドウ上で最大プーリングを実行した様子。
(**NLP では一般的に出力全体にわたってプーリングを適用する**。つまり各フィルタ(=>特徴マップ)からは **1 つの数値**が出力されることになる。)

![](https://tkengo.github.io/assets/img/understanding-convolutional-neural-networks-for-nlp/max-pooling.png)

### プーリング層を挟む理由

プーリング層をはさむ理由はいくつかある。

プーリングの特徴の 1 つは、出力される行列が固定サイズになるということ。

- たとえば 1000 個のフィルタがあってそれぞれのフィルタに対して最大プーリングを適用したとすると、入力のサイズやフィルタのサイズがどんなものであっても結果としては 1000 次元の出力が得られる。
- (1000個のフィルタ × 各フィルタ当たり1つのpooling出力 = 1000次元)
- これはつまり、**文章のサイズやフィルタのサイズが可変**だったとしても、**最終的に分類器へデータが渡ってくる時点では常に同じ次元**になっているということ。

２つ目に、プーリングは次元削減も行うが、単に次元を削減するのではなく必要な情報は維持したまま次元を削減してくれる。

- フィルタをある特定の特徴を抽出するためのものとして考えるのである。(ここは自明??フィルタ=スライド窓=カーネル=特徴検出器だし...!)
- たとえば “not amazing” などの否定が文章内に含まれているかどうかを検出するためのもの、という感じ。
  - もしこんなフレーズが文章のどこかにでてきた場合、その部分にフィルタを適用すると、出力される計算結果は大きな値になるだろう。
  - しかし、それ以外の別の部分にフィルタを適用した場合は、出力結果は小さな値になる。
- **最大プーリング**を適用することで、**文章中に “とある特徴” が存在するかどうかという情報は残ったまま**だが、その特徴が**実際にどこに出現するのかといった情報は失われる**ことになる！

しかし、このような位置に関する情報は本当に消えても大丈夫なのだろうか？答えは yes。n-grams モデルも似たようなもの。
位置に関する情報は失うが、フィルタによって捉えられた局所的な情報 - たとえば “not amazing” と “amazing not” の違いなど - は残ったままなのである。

3つ目に、画像認識での話だが、プーリングは位置と回転に不変性を与える。ある領域についてプーリングを行うと、画像が数ピクセルだけ移動や回転をしてもその出力はほぼ同じになる。それは最大プーリングが、微妙なピクセルの違いを無視して同じ値を抽出してきてくれるからである。

## チャンネル

最後はチャンネル。

チャンネルとは、**入力データを異なる視点から見たもの**と言える。

画像認識での例を挙げると、普通は画像は RGB (red, green, blue) の 3 チャンネルを持っている。
畳み込みはこれらのチャンネル全体に適用でき、その時のフィルタは各チャンネル毎に別々に用意してもいいし、同じものを使っても問題ない。

NLP では、**異なる単語埋め込み表現 (word2vec や GloVe など) でチャンネルを分けたり**、同じ文章を**異なる言語で表現**してみたり、また異なるフレーズで表現してみたり、という風にして**複数チャンネルを持たせる**ことができそう...!

# NLPへ適用されたCNN

以下では、自然言語処理に対して CNN を使ったアプリケーションの研究結果について見ていく。

CNN が得意なのは、**感情分析 (Sentiment Analysis)** や**スパム検出 (Spam Detection)**、**カテゴリ分類 (Topic Categorization)** などの分類問題。
畳み込みとプーリングの操作を適用すると、単語の局所的な位置情報は失われるので、品詞タグ付け (PoS Tagging) や固有表現抽出 (Entity Extraction) などを目的として、純粋な CNN を使うのはちょっと難しいらしい。


## キャラクターレベル CNN
